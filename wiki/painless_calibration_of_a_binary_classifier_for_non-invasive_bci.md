Can UI interventions assist usability outcomes in co-adaptive approaches to BCI calibration?

## milestone 1

- checkboxes after every n stimuli

- little red dot appears where the classification step would happen

## milestone 2

- 1st run: checkboxes for ground truth 

- subsequent runs: select what you were actually interested in (categorized by 'we thought these' 'we didn't think these'

## design questions

1. how relevant is the classifier itself to a UIST paper?

2. how can we ask meaningful questions about how this "integrative" "painless" interface affects usability outcomes? like.....versus.....what?  what are the outcomes?  user engagement/boredom?  classifier accuracy? user's feeling of control/frustration? etc

3. is it relevant to see if real-time BCI output affects any of the factors in (2)?